{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully split the dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratio = 0.2\n",
    "data_dir = '/mntnfs/med_data5/lijingquan/puppy/dataset'  \n",
    "train_dir = '/mntnfs/med_data5/lijingquan/puppy/train' \n",
    "test_dir = '/mntnfs/med_data5/lijingquan/puppy/test'  \n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for subdir in ['adult', 'puppy']:\n",
    "    img_dir = os.path.join(data_dir, subdir)\n",
    "    img_paths = [os.path.join(img_dir, fname) for fname in os.listdir(img_dir)]\n",
    "    \n",
    "    train_paths, test_paths = train_test_split(img_paths, test_size=ratio, random_state=42)\n",
    "    train_subdir = os.path.join(train_dir, subdir)\n",
    "    test_subdir = os.path.join(test_dir, subdir)\n",
    "    \n",
    "    os.makedirs(train_subdir, exist_ok=True)\n",
    "    os.makedirs(test_subdir, exist_ok=True)\n",
    "    \n",
    "    for path in train_paths:\n",
    "        shutil.copy(path, train_subdir)\n",
    "    \n",
    "    for path in test_paths:\n",
    "        shutil.copy(path, test_subdir)\n",
    "\n",
    "print(\"Successfully split the dataset, split ratio:\",ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dir = '/mntnfs/med_data5/lijingquan/puppy/train'  \n",
    "test_dir = '/mntnfs/med_data5/lijingquan/puppy/test'  \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),  \n",
    "    transforms.CenterCrop(224),  \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter) \n",
    "print(images.shape, labels.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': 0, 'puppy': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build model - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijingquan/miniconda3/envs/puppy/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),  \n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG16(num_classes=2)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.0001)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train model - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, num_epochs=5):\n",
    "    model.train()  \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, total=len(train_loader), leave=True, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            outputs = model(inputs)  \n",
    "            loss = criterion(outputs.squeeze(), labels.float()) \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()  \n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()  \n",
    "            # print(f'predicted / labels : {predicted.shape} / {labels.shape}')\n",
    "            correct += (predicted.view(-1) == labels).sum().item()  \n",
    "            # print(f'\\tpredicted.view: {predicted.view(-1).shape, predicted.view(-1)}')\n",
    "            # print(f'\\tlabels: {labels.shape, labels}')\n",
    "            total += labels.size(0) \n",
    "            # print(f'\\t> correct / total incrementation :\\t{(predicted.view(-1) == labels).sum().item()} / {labels.size(0)}')\n",
    "            pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'accuracy': (correct / total) * 100})\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader) \n",
    "        epoch_acc = (correct / total) * 100  \n",
    "        # print(f'correct / total : {correct} / {total}')\n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "        \n",
    "    return losses, accuracies\n",
    "\n",
    "# losses,accuracies = train_model(model, criterion, optimizer, train_loader, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 25/25 [01:20<00:00,  3.23s/it, loss=0.693, accuracy=50.7]\n",
      "Epoch 2/4: 100%|██████████| 25/25 [01:19<00:00,  3.19s/it, loss=0.693, accuracy=49.6]\n",
      "Epoch 3/4: 100%|██████████| 25/25 [01:21<00:00,  3.24s/it, loss=0.693, accuracy=50.2]\n",
      "Epoch 4/4: 100%|██████████| 25/25 [01:21<00:00,  3.27s/it, loss=0.693, accuracy=50]  \n"
     ]
    }
   ],
   "source": [
    "### Block for Hyperparameter Tuning & Model Training\n",
    "\n",
    "num_epochs = 4\n",
    "learn_rate = 0.0001\n",
    "# criteria = [nn.BCEWithLogitsLoss(), nn.BCELoss()]\n",
    "optimizer = optim.Adam(model.classifier[6].parameters(), lr=learn_rate)\n",
    "\n",
    "losses,accuracies = train_model(model, criterion, optimizer, train_loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vgg16_model.pth')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Model - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6932, Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float() \n",
    "            correct += (predicted.view(-1) == labels).sum().item()  \n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / len(test_loader)  \n",
    "    epoch_acc = (correct / total) * 100\n",
    "    print(f\"Test Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_acc:.2f}%\")\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test case -VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0, Prediction score: 0.4996\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  \n",
    "    return image\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    model.eval()\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        output = model(image)\n",
    "    \n",
    "    prediction = torch.sigmoid(output).item() \n",
    "    predicted_class = 1 if prediction > 0.5 else 0 \n",
    "    \n",
    "    return predicted_class, prediction\n",
    "\n",
    "image_path = '/mntnfs/med_data5/lijingquan/puppy/testcase/1.png'\n",
    "predicted_class, prediction = predict_image(model, image_path)\n",
    "print(f\"Predicted class: {predicted_class}, Prediction score: {prediction:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(MyResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)  # 2 blocks in layer1\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)  # 2 blocks in layer2\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)  # 2 blocks in layer3\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)  # 2 blocks in layer4\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = MyResNet18(num_classes=2).to(device)\n",
    "print(model_resnet18)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, num_epochs=5):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, total=len(train_loader), leave=True, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'accuracy': (correct / total) * 100})\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = (correct / total) * 100\n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 25/25 [00:54<00:00,  2.20s/it, loss=0.719, accuracy=55.4]\n",
      "Epoch 2/8: 100%|██████████| 25/25 [00:54<00:00,  2.17s/it, loss=0.638, accuracy=64]  \n",
      "Epoch 3/8: 100%|██████████| 25/25 [00:54<00:00,  2.16s/it, loss=0.529, accuracy=73.8]\n",
      "Epoch 4/8: 100%|██████████| 25/25 [00:54<00:00,  2.18s/it, loss=0.456, accuracy=79.9]\n",
      "Epoch 5/8: 100%|██████████| 25/25 [00:54<00:00,  2.18s/it, loss=0.357, accuracy=86]  \n",
      "Epoch 6/8: 100%|██████████| 25/25 [00:54<00:00,  2.20s/it, loss=0.33, accuracy=87.2] \n",
      "Epoch 7/8: 100%|██████████| 25/25 [00:54<00:00,  2.18s/it, loss=0.252, accuracy=90.6]\n",
      "Epoch 8/8: 100%|██████████| 25/25 [00:54<00:00,  2.18s/it, loss=0.185, accuracy=93.1]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 8\n",
    "losses, accuracies = train_model(model_resnet18, criterion, optimizer, train_loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model\n",
    "torch.save(model_resnet18.state_dict(), 'resnet18_model.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3646, Test Accuracy: 53.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = (correct / total) * 100\n",
    "    print(f\"Test Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_acc:.2f}%\")\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "test_loss, test_acc = evaluate_model(model_resnet18, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    model.eval()\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    _, prediction = torch.max(output, 1)\n",
    "    predicted_class = 'puppy' if prediction.item() == 1 else 'adult'\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Test a single image\n",
    "image_path = '/mntnfs/med_data5/lijingquan/puppy/testcase/2.png'\n",
    "print(predict_image(model_resnet18, image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. efficient net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (initial_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (initial_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (swish): SiLU()\n",
      "  (blocks): Sequential(\n",
      "    (0): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
      "      (depthwise_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "    (1): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
      "      (depthwise_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "    (2): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)\n",
      "      (depthwise_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "    (3): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240)\n",
      "      (depthwise_bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "    (4): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480)\n",
      "      (depthwise_bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "    (5): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(672, 672, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=672)\n",
      "      (depthwise_bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "    (6): EfficientNetBlock(\n",
      "      (expand_conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand_bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (depthwise_conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)\n",
      "      (depthwise_bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (project_conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (project_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=320, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EfficientNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor, stride=1):\n",
    "        super(EfficientNetBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        hidden_channels = int(in_channels * expansion_factor)\n",
    "        \n",
    "        self.expand_conv = nn.Conv2d(in_channels, hidden_channels, kernel_size=1)\n",
    "        self.expand_bn = nn.BatchNorm2d(hidden_channels)\n",
    "        \n",
    "        self.depthwise_conv = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, stride=stride, padding=1, groups=hidden_channels)\n",
    "        self.depthwise_bn = nn.BatchNorm2d(hidden_channels)\n",
    "        \n",
    "        self.project_conv = nn.Conv2d(hidden_channels, out_channels, kernel_size=1)\n",
    "        self.project_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.swish = nn.SiLU()\n",
    "\n",
    "        self.use_residual = (in_channels == out_channels and stride == 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.expand_conv(x)\n",
    "        x = self.expand_bn(x)\n",
    "        x = self.swish(x)\n",
    "        \n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.depthwise_bn(x)\n",
    "        x = self.swish(x)\n",
    "        \n",
    "        x = self.project_conv(x)\n",
    "        x = self.project_bn(x)\n",
    "        \n",
    "        if self.use_residual:\n",
    "            x += identity\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.initial_bn = nn.BatchNorm2d(32)\n",
    "        self.swish = nn.SiLU()\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            EfficientNetBlock(32, 16, expansion_factor=1),\n",
    "            EfficientNetBlock(16, 24, expansion_factor=6, stride=2),\n",
    "            EfficientNetBlock(24, 40, expansion_factor=6, stride=2),\n",
    "            EfficientNetBlock(40, 80, expansion_factor=6, stride=2),\n",
    "            EfficientNetBlock(80, 112, expansion_factor=6, stride=1),\n",
    "            EfficientNetBlock(112, 192, expansion_factor=6, stride=2),\n",
    "            EfficientNetBlock(192, 320, expansion_factor=6, stride=1)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Linear(320, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.swish(x)\n",
    "        \n",
    "        x = self.blocks(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "effnet_model = EfficientNet(num_classes=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "effnet_model = effnet_model.to(device)\n",
    "\n",
    "print(effnet_model)\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(effnet_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 25/25 [00:47<00:00,  1.90s/it, loss=0.688, accuracy=56.8]\n",
      "Epoch 2/30: 100%|██████████| 25/25 [00:47<00:00,  1.89s/it, loss=0.625, accuracy=66.6]\n",
      "Epoch 3/30: 100%|██████████| 25/25 [00:47<00:00,  1.91s/it, loss=0.562, accuracy=71.4]\n",
      "Epoch 4/30: 100%|██████████| 25/25 [00:47<00:00,  1.90s/it, loss=0.529, accuracy=74.6]\n",
      "Epoch 5/30: 100%|██████████| 25/25 [00:47<00:00,  1.90s/it, loss=0.462, accuracy=78.6]\n",
      "Epoch 6/30: 100%|██████████| 25/25 [00:47<00:00,  1.90s/it, loss=0.381, accuracy=84.9]\n",
      "Epoch 7/30:  76%|███████▌  | 19/25 [00:36<00:11,  1.90s/it, loss=0.317, accuracy=87]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 2\u001b[0m losses, accuracies \u001b[38;5;241m=\u001b[39m train_model(effnet_model, criterion, optimizer, train_loader, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs)\n",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     13\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/torchvision/datasets/folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/torchvision/datasets/folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/torchvision/datasets/folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/PIL/Image.py:993\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    991\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m    995\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/puppy/lib/python3.12/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "losses, accuracies = train_model(effnet_model, criterion, optimizer, train_loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4632, Test Accuracy: 61.00%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_model(effnet_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n"
     ]
    }
   ],
   "source": [
    "image_path = '/mntnfs/med_data5/lijingquan/puppy/testcase/2.png'\n",
    "print(predict_image(effnet_model, image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNetModel(\n",
      "  (initial_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (initial_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (initial_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (block1): DenseBlock(\n",
      "    (layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (trans1): TransitionLayer(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (block2): DenseBlock(\n",
      "    (layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(288, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Conv2d(352, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Sequential(\n",
      "        (0): Conv2d(384, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Sequential(\n",
      "        (0): Conv2d(416, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Sequential(\n",
      "        (0): Conv2d(448, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Sequential(\n",
      "        (0): Conv2d(480, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (trans2): TransitionLayer(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (block3): DenseBlock(\n",
      "    (layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(288, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(352, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(384, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(416, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Conv2d(448, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Conv2d(480, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Sequential(\n",
      "        (0): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Sequential(\n",
      "        (0): Conv2d(544, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Sequential(\n",
      "        (0): Conv2d(576, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Sequential(\n",
      "        (0): Conv2d(608, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Sequential(\n",
      "        (0): Conv2d(640, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Sequential(\n",
      "        (0): Conv2d(672, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Sequential(\n",
      "        (0): Conv2d(704, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Sequential(\n",
      "        (0): Conv2d(736, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Sequential(\n",
      "        (0): Conv2d(768, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Sequential(\n",
      "        (0): Conv2d(800, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): Sequential(\n",
      "        (0): Conv2d(832, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): Sequential(\n",
      "        (0): Conv2d(864, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): Sequential(\n",
      "        (0): Conv2d(896, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): Sequential(\n",
      "        (0): Conv2d(928, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): Sequential(\n",
      "        (0): Conv2d(960, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (23): Sequential(\n",
      "        (0): Conv2d(992, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (trans3): TransitionLayer(\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (block4): DenseBlock(\n",
      "    (layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(544, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(576, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(608, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(640, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(672, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Conv2d(704, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Conv2d(736, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Sequential(\n",
      "        (0): Conv2d(768, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Sequential(\n",
      "        (0): Conv2d(800, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Sequential(\n",
      "        (0): Conv2d(832, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Sequential(\n",
      "        (0): Conv2d(864, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Sequential(\n",
      "        (0): Conv2d(896, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Sequential(\n",
      "        (0): Conv2d(928, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Sequential(\n",
      "        (0): Conv2d(960, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Sequential(\n",
      "        (0): Conv2d(992, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            self._make_layer(in_channels + i * growth_rate, growth_rate) for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "    def _make_layer(self, in_channels, growth_rate):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(growth_rate),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            new_feat = layer(torch.cat(features, 1))\n",
    "            features.append(new_feat)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=2, growth_rate=32, num_blocks=[6, 12, 24, 16]):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        \n",
    "        self.initial_conv = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.initial_bn = nn.BatchNorm2d(64)\n",
    "        self.initial_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.block1 = DenseBlock(64, growth_rate, num_blocks[0])\n",
    "        self.trans1 = TransitionLayer(64 + num_blocks[0] * growth_rate, 128)\n",
    "        \n",
    "        self.block2 = DenseBlock(128, growth_rate, num_blocks[1])\n",
    "        self.trans2 = TransitionLayer(128 + num_blocks[1] * growth_rate, 256)\n",
    "        \n",
    "        self.block3 = DenseBlock(256, growth_rate, num_blocks[2])\n",
    "        self.trans3 = TransitionLayer(256 + num_blocks[2] * growth_rate, 512)\n",
    "        \n",
    "        self.block4 = DenseBlock(512, growth_rate, num_blocks[3])\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512 + num_blocks[3] * growth_rate, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.initial_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.initial_pool(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.trans1(x)\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        x = self.trans2(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        x = self.trans3(x)\n",
    "        \n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "densenet_model = DenseNetModel(num_classes=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "densenet_model = densenet_model.to(device)\n",
    "\n",
    "print(densenet_model)\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(densenet_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 25/25 [01:21<00:00,  3.25s/it, loss=0.716, accuracy=52.1]\n",
      "Epoch 2/20: 100%|██████████| 25/25 [01:21<00:00,  3.25s/it, loss=0.667, accuracy=60.2]\n",
      "Epoch 3/20: 100%|██████████| 25/25 [01:22<00:00,  3.32s/it, loss=0.658, accuracy=61.3]\n",
      "Epoch 4/20: 100%|██████████| 25/25 [01:20<00:00,  3.22s/it, loss=0.637, accuracy=64.6]\n",
      "Epoch 5/20: 100%|██████████| 25/25 [01:23<00:00,  3.34s/it, loss=0.598, accuracy=69.4]\n",
      "Epoch 6/20: 100%|██████████| 25/25 [01:17<00:00,  3.12s/it, loss=0.582, accuracy=69.1]\n",
      "Epoch 7/20: 100%|██████████| 25/25 [01:20<00:00,  3.20s/it, loss=0.587, accuracy=69.4]\n",
      "Epoch 8/20: 100%|██████████| 25/25 [01:19<00:00,  3.20s/it, loss=0.566, accuracy=71.1]\n",
      "Epoch 9/20: 100%|██████████| 25/25 [01:22<00:00,  3.31s/it, loss=0.547, accuracy=72.1]\n",
      "Epoch 10/20: 100%|██████████| 25/25 [01:19<00:00,  3.16s/it, loss=0.524, accuracy=73.8]\n",
      "Epoch 11/20: 100%|██████████| 25/25 [01:17<00:00,  3.12s/it, loss=0.496, accuracy=75.1]\n",
      "Epoch 12/20: 100%|██████████| 25/25 [01:24<00:00,  3.36s/it, loss=0.487, accuracy=78.1]\n",
      "Epoch 13/20: 100%|██████████| 25/25 [01:21<00:00,  3.25s/it, loss=0.49, accuracy=76.2] \n",
      "Epoch 14/20: 100%|██████████| 25/25 [01:22<00:00,  3.29s/it, loss=0.451, accuracy=79.4]\n",
      "Epoch 15/20: 100%|██████████| 25/25 [01:22<00:00,  3.31s/it, loss=0.434, accuracy=80.2]\n",
      "Epoch 16/20: 100%|██████████| 25/25 [01:28<00:00,  3.56s/it, loss=0.39, accuracy=81.9] \n",
      "Epoch 17/20: 100%|██████████| 25/25 [01:25<00:00,  3.43s/it, loss=0.34, accuracy=85.2] \n",
      "Epoch 18/20: 100%|██████████| 25/25 [01:19<00:00,  3.19s/it, loss=0.34, accuracy=83.1] \n",
      "Epoch 19/20: 100%|██████████| 25/25 [01:25<00:00,  3.40s/it, loss=0.327, accuracy=85.6]\n",
      "Epoch 20/20: 100%|██████████| 25/25 [01:17<00:00,  3.11s/it, loss=0.316, accuracy=86.5]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "losses, accuracies = train_model(densenet_model, criterion, optimizer, train_loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.8314, Test Accuracy: 55.00%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_model(densenet_model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
